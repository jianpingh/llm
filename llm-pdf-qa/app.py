# -*- coding: utf-8 -*-
import os
from dotenv import load_dotenv
from llama_index.core import (
    SimpleDirectoryReader,
    VectorStoreIndex,
    StorageContext,
    load_index_from_storage,
)
from llama_index.embeddings.openai import OpenAIEmbedding as BaseOpenAIEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb
import openai

# 0. æ¸…ç†ä»£ç†ç¯å¢ƒå˜é‡ï¼Œå¿…é¡»åœ¨ä»»ä½• openai å¯¼å…¥ä¹‹å‰
for var in ("HTTP_PROXY", "http_proxy", "HTTPS_PROXY", "https_proxy"):
    os.environ.pop(var, None)

# 1. åŠ è½½ .env
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")
API_BASE = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
if not API_KEY:
    raise ValueError("âŒ è¯·åœ¨ .env ä¸­è®¾ç½® OPENAI_API_KEY")

openai.api_key = API_KEY
openai.api_base = API_BASE

# 2. è‡ªå®šä¹‰å»é™¤ proxies å‚æ•°çš„åµŒå…¥ç±»
class OpenAIEmbeddingNoProxy(BaseOpenAIEmbedding):
    def _get_client(self):
        kw = self._get_credential_kwargs()
        kw.pop("proxies", None)
        from openai import OpenAI
        return OpenAI(**kw)

# 3. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
embed_model = OpenAIEmbeddingNoProxy(
    model_name="text-embedding-ada-002",
    openai_api_key=API_KEY,
    openai_api_base=API_BASE,
)

# 4. é…ç½®æœ¬åœ°æŒä¹…åŒ–è·¯å¾„å’Œé›†åˆå
PERSIST_DIR = "./chroma_db"
COLLECTION_NAME = "doc_collection"

# 5. åˆå§‹åŒ– Chroma æœ¬åœ°å®¢æˆ·ç«¯å¹¶è·å–ï¼ˆæˆ–åˆ›å»ºï¼‰é›†åˆ
chroma_client = chromadb.PersistentClient(path=PERSIST_DIR)
chroma_collection = chroma_client.get_or_create_collection(COLLECTION_NAME)

# 6. åˆ›å»ºå‘é‡å­˜å‚¨
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)

# 7. åˆ›å»º StorageContextï¼Œå¹¶åœ¨æ­¤æ—¶æŒ‡å®š persist_dir
storage_context = StorageContext.from_defaults(
    vector_store=vector_store,
    persist_dir=PERSIST_DIR,
)

# 8. å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•ï¼Œè‹¥ä¸å­˜åœ¨åˆ™æ„å»ºå¹¶æŒä¹…åŒ–
try:
    index = load_index_from_storage(storage_context)
    print("âœ… å·²åŠ è½½æœ¬åœ°å‘é‡ç´¢å¼•")
except ValueError:
    print("ğŸ”„ æœªæ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼Œæ­£åœ¨æ„å»ºæ–°çš„å‘é‡ç´¢å¼•...")
    documents = SimpleDirectoryReader("./docs").load_data()
    index = VectorStoreIndex.from_documents(
        documents,
        storage_context=storage_context,
        embed_model=embed_model,
    )
    storage_context.persist()
    print(f"âœ… å‘é‡ç´¢å¼•å·²æ„å»ºå¹¶ä¿å­˜åˆ° {PERSIST_DIR}")

# # --- æ‰“å°å‘é‡åº“ä¸­æ‰€æœ‰æ•°æ®çš„è¯¦ç»†ä¿¡æ¯ ---
# print("\nğŸ“Š å½“å‰å‘é‡åº“æ•°æ®è¯¦æƒ…ï¼š")
# data = chroma_collection.get(include=["documents", "metadatas", "embeddings"])
# for doc, meta, emb in zip(data["documents"], data["metadatas"], data["embeddings"]):
#     print(f"æ–‡æ¡£å†…å®¹: {doc}")
#     print(f"å…ƒæ•°æ®: {meta}")
#     print(f"å‘é‡é•¿åº¦: {len(emb)}, å‰5ç»´: {emb[:5]}")
#     print("-" * 40)

# 9. åˆ›å»ºæŸ¥è¯¢å¼•æ“å¹¶å¯åŠ¨äº¤äº’å¾ªç¯ï¼ˆä¸­æ–‡å›ç­”ï¼‰
query_engine = index.as_query_engine(response_mode="compact")
print("\nğŸ“š æ–‡æ¡£é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼Œè¾“å…¥ exit é€€å‡º")
while True:
    q = input("\nâ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š").strip()
    if q.lower() in ("exit", "quit", "é€€å‡º"):
        print("ğŸ‘‹ å†è§ï¼")
        break
    ans = query_engine.query(f"è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š{q}")
    print(f"\nğŸ’¡ å›ç­”ï¼ˆä¸­æ–‡ï¼‰ï¼š\n{ans.response}\n")
