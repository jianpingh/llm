# -*- coding: utf-8 -*-
import os
from dotenv import load_dotenv
from llama_index.core import (
    SimpleDirectoryReader,
    VectorStoreIndex,
    StorageContext,
    load_index_from_storage,
)
from llama_index.embeddings.openai import OpenAIEmbedding as BaseOpenAIEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb
import openai

# 0. æ¸…ç†ç³»ç»Ÿä»£ç†å˜é‡ï¼Œé˜²æ­¢æ„å¤–æŒ‚è½½ proxies
for proxy in ("HTTP_PROXY", "http_proxy", "HTTPS_PROXY", "https_proxy"):
    os.environ.pop(proxy, None)

# 1. åŠ è½½ .env
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")
API_BASE = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
if not API_KEY:
    raise ValueError("âŒ è¯·åœ¨ .env ä¸­è®¾ç½® OPENAI_API_KEY")

openai.api_key = API_KEY
openai.api_base = API_BASE

# 2. å»é™¤ proxies çš„ OpenAIEmbedding å­ç±»
class OpenAIEmbeddingNoProxy(BaseOpenAIEmbedding):
    def _get_client(self):
        kw = self._get_credential_kwargs()
        kw.pop("proxies", None)
        from openai import OpenAI
        return OpenAI(**kw)

embed_model = OpenAIEmbeddingNoProxy(
    model_name="text-embedding-ada-002",
    openai_api_key=API_KEY,
    openai_api_base=API_BASE,
)

# 3. Chroma æœ¬åœ°æŒä¹…åŒ–è®¾ç½®
PERSIST_DIR = "./chroma_db"
COLLECTION_NAME = "doc_collection"

# 4. åˆå§‹åŒ–æœ¬åœ° Chroma å®¢æˆ·ç«¯å¹¶è·å– Collection
chroma_client = chromadb.PersistentClient(path=PERSIST_DIR)
chroma_collection = chroma_client.get_or_create_collection(COLLECTION_NAME)

# 5. æ­£ç¡®ä¼ å…¥ chroma_collection å…³é”®å­—å‚æ•°
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)

# 6. æ„å»ºå­˜å‚¨ä¸Šä¸‹æ–‡
storage_context = StorageContext.from_defaults(vector_store=vector_store)

# 7. å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•ï¼Œå¤±è´¥åˆ™é‡å»ºå¹¶æŒä¹…åŒ–
try:
    index = load_index_from_storage(storage_context)
    print("âœ… å·²åŠ è½½æœ¬åœ°å‘é‡ç´¢å¼•")
except ValueError:
    print("ğŸ”„ æœªæ£€æµ‹åˆ°ç´¢å¼•ï¼Œæ­£åœ¨æ„å»ºæ–°çš„å‘é‡ç´¢å¼•...")
    documents = SimpleDirectoryReader("./docs").load_data()
    index = VectorStoreIndex.from_documents(
        documents,
        storage_context=storage_context,
        embed_model=embed_model,
    )
    index.storage_context.persist(PERSIST_DIR)
    print("âœ… å‘é‡ç´¢å¼•å·²æ„å»ºå¹¶ä¿å­˜")

# 8. åˆ›å»ºæŸ¥è¯¢å¼•æ“å¹¶è¿›å…¥äº¤äº’å¾ªç¯
query_engine = index.as_query_engine()
print("\nğŸ“š æ–‡æ¡£é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼Œè¾“å…¥ exit é€€å‡º")
while True:
    q = input("\nâ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š").strip()
    if q.lower() in ("exit", "quit", "é€€å‡º"):
        print("ğŸ‘‹ å†è§ï¼")
        break
    answer = query_engine.query(q)
    print(f"\nğŸ’¡ å›ç­”ï¼š\n{answer}\n")
