# å¯¼å…¥å¿…è¦çš„æ¨¡å—
# VectorStoreIndex ç”¨äºæ„å»ºå‘é‡ç´¢å¼•
# SimpleDirectoryReader ç”¨äºè¯»å–æœ¬åœ°æ–‡æ¡£
# OpenAIEmbedding ç”¨äºåµŒå…¥æ¨¡å‹
import os
from dotenv import load_dotenv
import openai
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
from llama_index.embeddings.openai import OpenAIEmbedding

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡ä¸­è·å– API å¯†é’¥å’Œä»£ç†åœ°å€
openai.api_key = os.getenv("OPENAI_API_KEY")
openai.api_base = os.getenv("OPENAI_API_BASE")

# æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
if not openai.api_key:
    raise ValueError("API å¯†é’¥æœªè®¾ç½®ï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ã€‚")

# åŠ è½½æœ¬åœ°æ–‡æ¡£ï¼Œè·¯å¾„ä¸º ./docs
documents = SimpleDirectoryReader("./docs").load_data()

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼Œä½¿ç”¨ OpenAI çš„ text-embedding-ada-002 æ¨¡å‹
embed_model = OpenAIEmbedding(
    model_name="text-embedding-ada-002"
)

# æ„å»ºå‘é‡ç´¢å¼•
index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)

# åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine()

# æ‰§è¡ŒæŸ¥è¯¢å¹¶æ‰“å°ç»“æœ
response = query_engine.query("æ–‡æ¡£çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)

# å¢åŠ ç”¨æˆ·è¾“å…¥é—®é¢˜å¹¶å›ç­”é—®é¢˜çš„é€»è¾‘
print("ğŸ“š æ–‡æ¡£é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼Œè¯·è¾“å…¥é—®é¢˜ï¼ˆè¾“å…¥ exit é€€å‡ºï¼‰")
while True:
    query = input("\nâ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
    if query.lower() in ["exit", "quit", "é€€å‡º"]:
        print("ğŸ‘‹ å†è§ï¼")
        break
    response = query_engine.query(query)
    print(f"ğŸ’¡ ç­”æ¡ˆï¼š\n{response}")
