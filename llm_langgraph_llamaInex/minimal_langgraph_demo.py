"""
æœ€ç®€ LangGraph é£æ ¼çš„ç ”ç©¶åŠ©æ‰‹æ¼”ç¤º
ä½¿ç”¨åŸç”Ÿ OpenAI APIï¼Œé¿å…æ‰€æœ‰ç‰ˆæœ¬å†²çª
"""

import os
import sys
import logging
from pathlib import Path
from typing import Dict, Any, List
import json
import re
import time

# ä½¿ç”¨åŸç”Ÿ OpenAI å®¢æˆ·ç«¯
try:
    import openai
except ImportError:
    print("è¯·å®‰è£… openai åŒ…: pip install openai")
    sys.exit(1)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# å¯¼å…¥é…ç½®
from config import config

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨"""
    
    def __init__(self):
        self.supported_extensions = ['.txt', '.md', '.py', '.js', '.html']
    
    def load_documents(self, directory: str) -> List[Dict[str, Any]]:
        """åŠ è½½ç›®å½•ä¸­çš„æ–‡æ¡£"""
        documents = []
        doc_dir = Path(directory)
        
        if not doc_dir.exists():
            logger.error(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
            return documents
        
        for file_path in doc_dir.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in self.supported_extensions:
                try:
                    content = self._read_file(file_path)
                    if content:
                        doc = {
                            'filename': file_path.name,
                            'path': str(file_path),
                            'content': content,
                            'size': len(content)
                        }
                        documents.append(doc)
                        logger.info(f"åŠ è½½æ–‡æ¡£: {file_path.name} ({len(content)} å­—ç¬¦)")
                except Exception as e:
                    logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
        
        logger.info(f"å…±åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        return documents
    
    def _read_file(self, file_path: Path) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return content[:3000]  # é™åˆ¶é•¿åº¦
        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
                return content[:3000]
            except:
                return ""


class SimpleRetriever:
    """ç®€å•æ£€ç´¢å™¨"""
    
    def __init__(self, documents: List[Dict[str, Any]]):
        self.documents = documents
    
    def retrieve(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        if not self.documents:
            return []
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        query_words = set(re.findall(r'\w+', query.lower()))
        scored_docs = []
        
        for doc in self.documents:
            content_words = set(re.findall(r'\w+', doc['content'].lower()))
            score = len(query_words.intersection(content_words))
            
            if score > 0:
                scored_docs.append((doc, score))
        
        # æ’åºå¹¶è¿”å›top_k
        scored_docs.sort(key=lambda x: x[1], reverse=True)
        return [doc for doc, score in scored_docs[:top_k]]


class LangGraphWorkflow:
    """LangGraph é£æ ¼çš„å·¥ä½œæµ"""
    
    def __init__(self, api_key: str):
        # è®¾ç½®OpenAI APIå¯†é’¥
        openai.api_key = api_key
        self.documents = []
        self.retriever = None
        
        logger.info("LangGraph é£æ ¼å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ")
    
    def load_documents(self, directory: str) -> Dict[str, Any]:
        """åŠ è½½æ–‡æ¡£ - å·¥ä½œæµèŠ‚ç‚¹1"""
        try:
            logger.info("æ‰§è¡ŒèŠ‚ç‚¹: æ–‡æ¡£åŠ è½½")
            
            loader = DocumentLoader()
            self.documents = loader.load_documents(directory)
            self.retriever = SimpleRetriever(self.documents)
            
            return {
                "status": "success",
                "message": f"æˆåŠŸåŠ è½½ {len(self.documents)} ä¸ªæ–‡æ¡£",
                "document_count": len(self.documents)
            }
        except Exception as e:
            logger.error(f"æ–‡æ¡£åŠ è½½èŠ‚ç‚¹å¤±è´¥: {str(e)}")
            return {"status": "error", "message": str(e)}
    
    def retrieve_context(self, query: str) -> Dict[str, Any]:
        """æ£€ç´¢ä¸Šä¸‹æ–‡ - å·¥ä½œæµèŠ‚ç‚¹2"""
        try:
            logger.info("æ‰§è¡ŒèŠ‚ç‚¹: ä¸Šä¸‹æ–‡æ£€ç´¢")
            
            if not self.retriever:
                return {"relevant_docs": [], "context": ""}
            
            relevant_docs = self.retriever.retrieve(query, top_k=3)
            context = "\n\n".join([f"æ–‡æ¡£: {doc['filename']}\nå†…å®¹: {doc['content'][:500]}..." 
                                  for doc in relevant_docs])
            
            logger.info(f"æ£€ç´¢åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£")
            
            return {
                "relevant_docs": relevant_docs,
                "context": context,
                "doc_count": len(relevant_docs)
            }
            
        except Exception as e:
            logger.error(f"ä¸Šä¸‹æ–‡æ£€ç´¢èŠ‚ç‚¹å¤±è´¥: {str(e)}")
            return {"relevant_docs": [], "context": "", "doc_count": 0}
    
    def analyze_query(self, query: str, context: str) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢ - å·¥ä½œæµèŠ‚ç‚¹3"""
        try:
            logger.info("æ‰§è¡ŒèŠ‚ç‚¹: æŸ¥è¯¢åˆ†æ")
            
            prompt = f"""ä½œä¸ºä¸€ä¸ªç ”ç©¶åˆ†æå¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼š

ç”¨æˆ·æŸ¥è¯¢: {query}

ç›¸å…³æ–‡æ¡£å†…å®¹:
{context[:1500] if context else "æ— ç›¸å…³æ–‡æ¡£"}

è¯·æä¾›ï¼š
1. æŸ¥è¯¢æ„å›¾åˆ†æ
2. å…³é”®ä¿¡æ¯è¦ç‚¹
3. å›ç­”æ€è·¯

ä¿æŒåˆ†æç®€æ´æ¸…æ™°ã€‚"""

            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=800
            )
            
            analysis = response.choices[0].message.content
            logger.info("æŸ¥è¯¢åˆ†æå®Œæˆ")
            
            return {"analysis": analysis, "status": "success"}
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†æèŠ‚ç‚¹å¤±è´¥: {str(e)}")
            return {"analysis": f"åˆ†æå¤±è´¥: {str(e)}", "status": "error"}
    
    def generate_response(self, query: str, analysis: str, context: str) -> Dict[str, Any]:
        """ç”Ÿæˆå›ç­” - å·¥ä½œæµèŠ‚ç‚¹4"""
        try:
            logger.info("æ‰§è¡ŒèŠ‚ç‚¹: å›ç­”ç”Ÿæˆ")
            
            prompt = f"""åŸºäºåˆ†æç»“æœå’Œç›¸å…³æ–‡æ¡£ï¼Œä¸ºç”¨æˆ·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„å›ç­”ï¼š

ç”¨æˆ·æŸ¥è¯¢: {query}

åˆ†æç»“æœ: {analysis}

ç›¸å…³æ–‡æ¡£:
{context[:2000] if context else "æ— ç›¸å…³æ–‡æ¡£"}

è¯·æä¾›ï¼š
1. ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜
2. è¯¦ç»†è§£é‡Šå’Œè¯´æ˜
3. ç›¸å…³ç¤ºä¾‹æˆ–å»ºè®®
4. æ€»ç»“è¦ç‚¹

ç¡®ä¿å›ç­”ç»“æ„æ¸…æ™°ã€å†…å®¹å‡†ç¡®ã€æœ‰å®ç”¨ä»·å€¼ã€‚"""

            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=1500
            )
            
            answer = response.choices[0].message.content
            logger.info("å›ç­”ç”Ÿæˆå®Œæˆ")
            
            return {"response": answer, "status": "success"}
            
        except Exception as e:
            logger.error(f"å›ç­”ç”ŸæˆèŠ‚ç‚¹å¤±è´¥: {str(e)}")
            return {"response": f"å›ç­”ç”Ÿæˆå¤±è´¥: {str(e)}", "status": "error"}
    
    def execute_workflow(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´å·¥ä½œæµ"""
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œ LangGraph å·¥ä½œæµ: {query}")
            
            workflow_state = {
                "query": query,
                "step_count": 0,
                "execution_time": time.time()
            }
            
            # èŠ‚ç‚¹1: æ£€ç´¢ä¸Šä¸‹æ–‡
            logger.info("æ­¥éª¤1: æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡")
            context_result = self.retrieve_context(query)
            workflow_state["step_count"] += 1
            workflow_state["relevant_docs"] = context_result["relevant_docs"]
            workflow_state["context"] = context_result["context"]
            
            # èŠ‚ç‚¹2: åˆ†ææŸ¥è¯¢
            logger.info("æ­¥éª¤2: åˆ†ææŸ¥è¯¢æ„å›¾")  
            analysis_result = self.analyze_query(query, context_result["context"])
            workflow_state["step_count"] += 1
            workflow_state["analysis"] = analysis_result["analysis"]
            
            # èŠ‚ç‚¹3: ç”Ÿæˆå›ç­”
            logger.info("æ­¥éª¤3: ç”Ÿæˆæœ€ç»ˆå›ç­”")
            response_result = self.generate_response(
                query, 
                analysis_result["analysis"], 
                context_result["context"]
            )
            workflow_state["step_count"] += 1
            workflow_state["response"] = response_result["response"]
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            workflow_state["execution_time"] = time.time() - workflow_state["execution_time"]
            workflow_state["status"] = "success"
            
            logger.info("LangGraph å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
            return workflow_state
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "query": query,
                "response": f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "step_count": 0,
                "status": "error"
            }


class MinimalLangGraphApp:
    """æœ€ç®€ LangGraph é£æ ¼åº”ç”¨"""
    
    def __init__(self):
        self.config = config
        self.workflow = None
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        Path("logs").mkdir(exist_ok=True)
        
        logger.info("=" * 60)
        logger.info("æœ€ç®€ LangGraph ç ”ç©¶åŠ©æ‰‹å¯åŠ¨")
        logger.info("=" * 60)
        
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        try:
            logger.info("åˆå§‹åŒ– LangGraph å·¥ä½œæµ...")
            
            # è·å–OpenAIé…ç½®
            openai_config = self.config.get_openai_config()
            api_key = openai_config['api_key']
            
            if not api_key:
                raise ValueError("OpenAI API å¯†é’¥æœªé…ç½®")
            
            self.workflow = LangGraphWorkflow(api_key)
            logger.info("åº”ç”¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åº”ç”¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def setup_documents(self, documents_dir: str = "./sample_documents") -> Dict[str, Any]:
        """è®¾ç½®æ–‡æ¡£"""
        return self.workflow.load_documents(documents_dir)
    
    def query(self, question: str) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢"""
        return self.workflow.execute_workflow(question)
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€"""
        openai_config = self.config.get_openai_config()
        
        return {
            "application": "æœ€ç®€ LangGraph ç ”ç©¶åŠ©æ‰‹",
            "model": openai_config['model'],
            "document_count": len(self.workflow.documents) if self.workflow else 0,
            "environment": self.config.environment,
            "status": "è¿è¡Œä¸­"
        }


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºåº”ç”¨
        app = MinimalLangGraphApp()
        
        # æ˜¾ç¤ºçŠ¶æ€
        status = app.get_status()
        print("\n" + "=" * 60)
        print("ğŸ”¬ LangGraph ç ”ç©¶åŠ©æ‰‹çŠ¶æ€")
        print("=" * 60)
        for key, value in status.items():
            print(f"{key}: {value}")
        
        # è®¾ç½®æ–‡æ¡£
        print("\n" + "-" * 40)
        print("ğŸ“š è®¾ç½®æ–‡æ¡£åº“...")
        print("-" * 40)
        
        setup_result = app.setup_documents()
        print(f"çŠ¶æ€: {setup_result['status']}")
        print(f"æ¶ˆæ¯: {setup_result['message']}")
        
        if setup_result['status'] == 'success':
            # æµ‹è¯•æŸ¥è¯¢
            print("\n" + "-" * 40)
            print("ğŸ§  LangGraph å·¥ä½œæµæµ‹è¯•")
            print("-" * 40)
            
            test_queries = [
                "ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿå®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
                "LlamaIndex çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
                "å¦‚ä½•æ„å»ºä¸€ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®ï¼Ÿ",
                "Python æ•°æ®ç§‘å­¦æœ‰å“ªäº›é‡è¦å·¥å…·ï¼Ÿ"
            ]
            
            for i, query in enumerate(test_queries, 1):
                print(f"\nğŸ” æŸ¥è¯¢ {i}: {query}")
                print("-" * 30)
                
                result = app.query(query)
                
                if result['status'] == 'success':
                    # æ˜¾ç¤ºæ‰§è¡Œä¿¡æ¯
                    print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f} ç§’")
                    print(f"ğŸ“Š å¤„ç†æ­¥éª¤: {result['step_count']}")
                    print(f"ğŸ“‹ ç›¸å…³æ–‡æ¡£: {len(result.get('relevant_docs', []))} ä¸ª")
                    
                    # æ˜¾ç¤ºåˆ†æ
                    if 'analysis' in result:
                        analysis = result['analysis']
                        print(f"\nğŸ¯ åˆ†æç»“æœ:")
                        if len(analysis) > 200:
                            print(f"{analysis[:200]}...")
                        else:
                            print(analysis)
                    
                    # æ˜¾ç¤ºå›ç­”
                    response = result['response']
                    print(f"\nğŸ’¡ å›ç­”:")
                    if len(response) > 300:
                        print(f"{response[:300]}...")
                    else:
                        print(response)
                        
                else:
                    print(f"âŒ é”™è¯¯: {result['response']}")
        
        print("\n" + "=" * 60)
        print("âœ… LangGraph æ¼”ç¤ºå®Œæˆ")
        print("=" * 60)
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"åº”ç”¨è¿è¡Œå¤±è´¥: {str(e)}")
        print(f"\nâŒ é”™è¯¯: {str(e)}")


if __name__ == "__main__":
    main()
