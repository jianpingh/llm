# LangGraph å®ç”¨æŒ‡å—

## ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ

LangGraph æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºæœ‰çŠ¶æ€ã€å¤šå‚ä¸è€…åº”ç”¨ç¨‹åºçš„åº“ï¼ŒåŸºäº LangChain æ„å»ºã€‚å®ƒæ‰©å±•äº† LangChain Expression Languageï¼Œå¢åŠ äº†å¾ªç¯ã€æŒä¹…æ€§å’Œäººæœºäº¤äº’çš„èƒ½åŠ›ã€‚

## æ ¸å¿ƒæ¦‚å¿µ

### 1. çŠ¶æ€å›¾ï¼ˆStateGraphï¼‰

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict

class GraphState(TypedDict):
    messages: list
    user_input: str
    result: str

# åˆ›å»ºçŠ¶æ€å›¾
workflow = StateGraph(GraphState)
```

### 2. èŠ‚ç‚¹ï¼ˆNodesï¼‰

èŠ‚ç‚¹æ˜¯å›¾ä¸­çš„å¤„ç†å•å…ƒï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯ä¸€ä¸ªå‡½æ•°ï¼š

```python
def process_input(state):
    """å¤„ç†ç”¨æˆ·è¾“å…¥çš„èŠ‚ç‚¹"""
    user_input = state["user_input"]
    # å¤„ç†é€»è¾‘
    return {"result": f"å¤„ç†ç»“æœ: {user_input}"}

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("process", process_input)
```

### 3. è¾¹ï¼ˆEdgesï¼‰

è¾¹å®šä¹‰äº†èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å…³ç³»ï¼š

```python
# æ·»åŠ è¾¹
workflow.add_edge("process", END)

# æ¡ä»¶è¾¹
def should_continue(state):
    if state["result"]:
        return "end"
    return "continue"

workflow.add_conditional_edges(
    "process",
    should_continue,
    {"end": END, "continue": "process"}
)
```

## å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šæ™ºèƒ½å¯¹è¯ç³»ç»Ÿ

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages

class ConversationState(TypedDict):
    messages: Annotated[list, add_messages]
    context: str
    intent: str

def analyze_intent(state):
    """åˆ†æç”¨æˆ·æ„å›¾"""
    last_message = state["messages"][-1]
    # æ„å›¾åˆ†æé€»è¾‘
    intent = classify_intent(last_message.content)
    return {"intent": intent}

def generate_response(state):
    """ç”Ÿæˆå›å¤"""
    intent = state["intent"]
    context = state["context"]
    # ç”Ÿæˆå›å¤é€»è¾‘
    response = create_response(intent, context)
    return {"messages": [AIMessage(content=response)]}

# æ„å»ºå·¥ä½œæµ
workflow = StateGraph(ConversationState)
workflow.add_node("analyze", analyze_intent)
workflow.add_node("respond", generate_response)

workflow.add_edge("analyze", "respond")
workflow.add_edge("respond", END)

workflow.set_entry_point("analyze")
app = workflow.compile()
```

### æ¡ˆä¾‹2ï¼šæ–‡æ¡£å¤„ç†æµæ°´çº¿

```python
class DocumentState(TypedDict):
    raw_text: str
    chunks: list
    embeddings: list
    summary: str

def chunk_document(state):
    """æ–‡æ¡£åˆ†å—"""
    text = state["raw_text"]
    chunks = split_text(text, chunk_size=1000)
    return {"chunks": chunks}

def create_embeddings(state):
    """åˆ›å»ºåµŒå…¥å‘é‡"""
    chunks = state["chunks"]
    embeddings = [embed_text(chunk) for chunk in chunks]
    return {"embeddings": embeddings}

def summarize_document(state):
    """æ–‡æ¡£æ‘˜è¦"""
    chunks = state["chunks"]
    summary = generate_summary(chunks)
    return {"summary": summary}

# æ„å»ºæ–‡æ¡£å¤„ç†æµæ°´çº¿
doc_workflow = StateGraph(DocumentState)
doc_workflow.add_node("chunk", chunk_document)
doc_workflow.add_node("embed", create_embeddings)
doc_workflow.add_node("summarize", summarize_document)

doc_workflow.add_edge("chunk", "embed")
doc_workflow.add_edge("embed", "summarize")
doc_workflow.add_edge("summarize", END)

doc_workflow.set_entry_point("chunk")
```

## é«˜çº§ç‰¹æ€§

### 1. äººæœºäº¤äº’

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

def human_review(state):
    """éœ€è¦äººå·¥å®¡æ ¸çš„èŠ‚ç‚¹"""
    # è¿™é‡Œä¼šæš‚åœæ‰§è¡Œï¼Œç­‰å¾…äººå·¥è¾“å…¥
    return {"status": "pending_review"}

workflow.add_node("review", human_review)

# ç¼–è¯‘æ—¶æ·»åŠ æ£€æŸ¥ç‚¹
memory = MemorySaver()
app = workflow.compile(checkpointer=memory)
```

### 2. æŒä¹…åŒ–çŠ¶æ€

```python
# ä½¿ç”¨æ•°æ®åº“ä½œä¸ºæ£€æŸ¥ç‚¹
from langgraph.checkpoint.postgres import PostgresSaver

checkpointer = PostgresSaver.from_conn_string("postgresql://...")
app = workflow.compile(checkpointer=checkpointer)

# è¿è¡Œæ—¶æŒ‡å®šçº¿ç¨‹ID
config = {"configurable": {"thread_id": "user_123"}}
result = app.invoke(initial_state, config=config)
```

### 3. æµå¼å¤„ç†

```python
# æµå¼æ‰§è¡Œ
for chunk in app.stream(initial_state, config=config):
    print(f"èŠ‚ç‚¹ {chunk['node']} å®Œæˆ")
    print(f"çŠ¶æ€æ›´æ–°: {chunk['state']}")
```

## æœ€ä½³å®è·µ

### 1. çŠ¶æ€è®¾è®¡

- ä¿æŒçŠ¶æ€ç»“æ„ç®€å•æ¸…æ™°
- ä½¿ç”¨ç±»å‹æ³¨è§£æé«˜ä»£ç å¯è¯»æ€§
- é¿å…åœ¨çŠ¶æ€ä¸­å­˜å‚¨å¤§é‡æ•°æ®

### 2. èŠ‚ç‚¹è®¾è®¡

- æ¯ä¸ªèŠ‚ç‚¹èŒè´£å•ä¸€
- èŠ‚ç‚¹å‡½æ•°åº”è¯¥æ˜¯çº¯å‡½æ•°
- åˆç†å¤„ç†å¼‚å¸¸æƒ…å†µ

### 3. é”™è¯¯å¤„ç†

```python
def safe_node(state):
    try:
        # èŠ‚ç‚¹é€»è¾‘
        result = process_data(state)
        return {"result": result, "error": None}
    except Exception as e:
        return {"result": None, "error": str(e)}
```

### 4. æ€§èƒ½ä¼˜åŒ–

- ä½¿ç”¨å¼‚æ­¥èŠ‚ç‚¹å¤„ç†å¹¶å‘
- é€‚å½“ä½¿ç”¨ç¼“å­˜æœºåˆ¶
- ç›‘æ§å›¾æ‰§è¡Œæ€§èƒ½

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†å¾ªç¯é€»è¾‘ï¼Ÿ

ä½¿ç”¨æ¡ä»¶è¾¹åˆ›å»ºå¾ªç¯ï¼š

```python
def should_continue(state):
    if state["iteration_count"] < 5:
        return "continue"
    return "end"

workflow.add_conditional_edges(
    "process",
    should_continue,
    {"continue": "process", "end": END}
)
```

### Q2: å¦‚ä½•å®ç°å¹¶è¡Œå¤„ç†ï¼Ÿ

```python
from langgraph.graph import StateGraph, END

# æ·»åŠ å¹¶è¡ŒèŠ‚ç‚¹
workflow.add_node("parallel_1", node_1)
workflow.add_node("parallel_2", node_2)

# ä»åŒä¸€èŠ‚ç‚¹è¿æ¥åˆ°å¤šä¸ªå¹¶è¡ŒèŠ‚ç‚¹
workflow.add_edge("start", "parallel_1")
workflow.add_edge("start", "parallel_2")

# æ±‡èšèŠ‚ç‚¹
workflow.add_node("merge", merge_results)
workflow.add_edge("parallel_1", "merge")
workflow.add_edge("parallel_2", "merge")
```

## æ€»ç»“

LangGraph ä¸ºæ„å»ºå¤æ‚çš„AIåº”ç”¨æä¾›äº†å¼ºå¤§çš„å›¾è®¡ç®—æ¡†æ¶ã€‚é€šè¿‡çŠ¶æ€å›¾ã€èŠ‚ç‚¹å’Œè¾¹çš„ç»„åˆï¼Œå¯ä»¥å®ç°å„ç§å¤æ‚çš„ä¸šåŠ¡é€»è¾‘ï¼ŒåŒæ—¶ä¿æŒä»£ç çš„æ¸…æ™°å’Œå¯ç»´æŠ¤æ€§ã€‚

å…³é”®ä¼˜åŠ¿ï¼š
- ğŸ”„ æ”¯æŒå¾ªç¯å’Œæ¡ä»¶é€»è¾‘
- ğŸ’¾ å†…ç½®çŠ¶æ€æŒä¹…åŒ–
- ğŸ¤ äººæœºäº¤äº’æ”¯æŒ
- ğŸ“Š å¯è§†åŒ–æ‰§è¡Œæµç¨‹
- ğŸ”§ æ˜“äºè°ƒè¯•å’Œç»´æŠ¤
